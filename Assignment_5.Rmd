---
title: "FML - Assignment 5"
author: "Teja Tarapatla"
date: "2024-04-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# The neccesary libraries
library(cluster)
```

```{r}
library(caret)
```

```{r}
library(dendextend)
```

```{r}
# The neccesary libraries
library(knitr)
```

```{r}
library(factoextra)
```

```{r}

#Bringing in the cereals data set
Cereals_data <- read.csv("C:/Users/divya/Downloads/Cereals.csv")

# Extricate columns 4 to 16 from the 'Cereals_data' dataset and store them in a unused information outline 'Cereals.data'
Cereals.data <- data.frame(Cereals_data[, 4:16])

```

```{r}

#Evacuating the lost values from the information
Cereals.data <- na.omit(Cereals.data)
##Data normalization and data scaling
cereals.norm <- scale(Cereals.data)

```

```{r}

#Applying various leveled clustering to the information utilizing euclidean separate to normalize estimations
Euclidean_Dist <- dist(cereals.norm, method = "euclidean")
hierarch_clust_complete <- hclust(Euclidean_Dist, method = "complete")

#plotting the dendogram
plot(hierarch_clust_complete, cex = 0.7, hang = -1)

```

```{r}

##Utilizing agnes() work to perform clustering with single, complete,average, ward linkages separately.

hierarch_clust_single <- agnes(cereals.norm, method = "single")
hierarch_clust_complete <- agnes(cereals.norm, method = "complete")
hierarch_clust_average <- agnes(cereals.norm, method = "average")
hierarch_clust_ward <- agnes(cereals.norm, method = "ward")

```


```{r}

# printing 'ac' property esteem of the various leveled cluster.single linkage
print(hierarch_clust_single$ac)

```

```{r}

# printing 'ac' property esteem of the various leveled cluster.complete linkage
print(hierarch_clust_complete$ac)

```

```{r}

# printing 'ac' trait esteem of the progressive cluster.average linkage
print(hierarch_clust_average$ac)

```

```{r}

# printing 'ac' trait esteem of the various leveled cluster.ward linkage
print(hierarch_clust_ward$ac)

```

##The leading result we gotten from the yield over is 0.904, or ward linkage. cutting the Dendrogram and plotting the agnes utilizing the Ward strategy. We’ll utilize the remove to induce k = 4.

## Selecting or Choosing Clusters

```{r}

#Plotting the dendrogram utilizing pltree work from various leveled clustering result (Utilizing Ward strategy)
pltree(hierarch_clust_ward, cex = 0.7, hang = -1, main = "Dendrogram of agnes (Using Ward linkage)")

#Highlighting clusters by drawing rectangles around clusters (in this case, k = 5 clusters)
rect.hclust(hierarch_clust_ward, k = 5, border = 1:4)

```

```{r}

# Relegating cluster names to each perception utilizing cutree work based on Ward's various leveled clustering with k=5 clusters
Cluster1 <- cutree(hierarch_clust_ward, k=5)

#Making a unused dataframe (data2) combining the first information (cereals.norm) and the cluster names
data2 <- as.data.frame(cbind(cereals.norm,Cluster1))

```

```{r}

# We'll select 5 clusters after watching the separate.
# Creating Partitions
set.seed(123)
# Making Part1 by selecting columns 1 to 50 from the Cereals.data dataset
Part1 <- Cereals.data[1:50,]
# Making Part2 by selecting lines 51 to 74 from the Cereals.data dataset
Part2 <- Cereals.data[51:74,]

```

```{r}

#Performing various leveled Clustering, considering k = 5 for the given linkages single, total, normal and ward individually.
AGNES_single <- agnes(scale(Part1), method = "single")
AGNES_complete <- agnes(scale(Part1), method = "complete")
AGNES_average <- agnes(scale(Part1), method = "average")
AGNES_ward <- agnes(scale(Part1), method = "ward")

#Combining the 'ac' quality comes about from diverse progressive clustering strategies (single, total, normal, ward linkages individually)
cbind(single=AGNES_single$ac , complete=AGNES_complete$ac , average= AGNES_average$ac , ward= AGNES_ward$ac)

```

```{r}

# Plotting the dendrogram utilizing pltree work for various leveled clustering result (AGNES_ward) with indicated parameters
pltree(AGNES_ward, cex = 0.6, hang = -1, main = "Dendogram of Agnes with Partitioned Data (Using Ward linkage)")

# Highlighting clusters by drawing rectangles around clusters (in this case, k = 5 clusters) based on AGNES_ward result
rect.hclust(AGNES_ward, k = 5, border = 1:4)

```

```{r}

# Doling out cluster names to perceptions based on AGNES various leveled clustering with k=5 clusters
Cluster2 <- cutree(AGNES_ward, k = 5)

```

```{r}

# Calculating the centeroids
# Combining Part1 and Cluster2 into a modern dataframe named 'result'
result <- as.data.frame(cbind(Part1, Cluster2))

# Sifting columns in 'result' where the 'Cluster2 ' column esteem rises to 1
result[result$Cluster2==1,]

```

```{r}

# Calculating the centroid (cruel) for the columns of 'result' dataframe where 'Cluster2 ' column esteem is break even with to 1
Centroid1 <- colMeans(result[result$cut_2==1,])

# Calculating the centroid (unfeeling) for the columns of 'result' dataframe where 'Cluster2 ' column regard is break indeed with to 1
result[result$Cluster2==2,]


```

```{r}

# Calculating the centroid (cruel) for the columns of 'result' dataframe where 'Cluster2 ' column esteem is rise to to 2
Centroid2 <- colMeans(result[result$Cluster2==2,])
# Showing lines in 'result' dataframe where the 'Cluster2 ' column esteem is break even with to 3
result[result$Cluster2==3,]


```

```{r}

# Calculating the centroid (cruel) for the columns of 'result' dataframe where 'Cluster2 ' column esteem is break even with to 3
Centroid3 <- colMeans(result[result$Cluster2 ==3,])
# Showing lines in 'result' dataframe where the 'Cluster2 ' column esteem is break even with to 4result[result$cluster02 ==4,]

```

```{r}

# Calculating the centroid (cruel) for the columns of 'result' dataframe where 'Cluster2 ' column esteem is rise to to 4
Centroid4 <- colMeans(result[result$Cluster2 ==4,])
# Calculating the centroid (unfeeling) for the columns of 'result' dataframe where 'Cluster2 ' column regard is rise to to 4
Centroids <- rbind(Centroid1, Centroid2, Centroid3, Centroid4)
# Making a unused dataframe 'x2' by combining 'Centroids' information (barring the 14th column) with 'Part2'
x2 <- as.data.frame(rbind(Centroids[,-14], Part2))

```


```{r}

#Calculating the Separate
# Calculating separations between focuses in 'x2' utilizing the get_dist function
Distance1 <- dist(x2)
# Changing over the separate protest 'Distance1' into a network
Matrix1 <- as.matrix(Distance1)
# Making a dataframe 'data1' to store information and cluster assignments
data1 <- data.frame(data=seq(1,nrow(Part2),1), Clusters = rep(0,nrow(Part2)))
# Circling through each push of Part2 to allot clusters based on least separations
for(i in 1:nrow(Part2))
{data1[i,2] <- which.min(Matrix1[i+4, 1:4])}
# Showing the coming about data1 containing information files and doled out clusters
data1

```

```{r}

# Combining Cluster1 values from data2 for lines 51 to 74 with Clusters values from data1
cbind(data2$Cluster1[51:74], data1$Clusters)

```

```{r}

# Making a table to compare balance between Cluster1 values from data2 (columns 51 to 74) and Clusters values from data1
table(data2$Cluster1[51:74] == data1$Clusters)

```

The demonstrate shows up to be somewhat steady, as prove by the 12 TRUE and 12 FALSE comes about.
The basic open schools would like to select a set of cereals to incorporate in their day by day cafeterias. Each day a distinctive cereal is advertised, but all cereals ought to bolster a sound eat less. For this objective, you’re asked to discover a cluster of “healthy cereals.” Ought to the information be normalized? On the off chance that not, how ought to they be utilized within the cluster investigation

```{r}

#Making copy of 'Cereals.data' data frame named 'Healthy_Cereals'
Healthy_Cereals <-Cereals.data
# Preparing new data frame 'Healthy_Cereals_new' by deleting rows with missing values from 'Healthy_Cereals'
Healthy_Cereals_new <- na.omit(Healthy_Cereals)
# Mixing 'Healthy_Cereals_new' data frame with 'Cluster1' extracted from previous operations into 'Healthy_Cluster'
Healthy_Cluster <- cbind(Healthy_Cereals_new, Cluster1)

```

```{r}

# Displaying rows in 'Healthy_Cluster' dataframe where the 'Cluster1' column value is equal to 1
Healthy_Cluster[Healthy_Cluster$Cluster1==1,]

```

```{r}

# Showing lines in 'Healthy_Cluster' dataframe where the 'Cluster1' column esteem is rise to to 2
Healthy_Cluster[Healthy_Cluster$Cluster1==2,]

```

```{r}

# Displaying rows in 'Healthy_Cluster' dataframe where the 'Cluster1' column value is equal to 3
Healthy_Cluster[Healthy_Cluster$Cluster1==3,]

```

```{r}

# showing columns from the 'Healthy_Cluster' dataframe where the 'Cluster1' column esteem is break even with to 4
Healthy_Cluster[Healthy_Cluster$Cluster1==4,]

```

```{r}

#Cruel evaluations to decide the most excellent cluster.
# Calculating the cruel of 'rating' values for columns in 'Healthy_Cluster' dataframe where 'Cluster1' column esteem is break even with to 1
mean(Healthy_Cluster[Healthy_Cluster$Cluster1==1,"rating"])

```

```{r}

#Calculating the cruel of 'rating' values for columns in 'Healthy_Cluster' dataframe where 'Cluster1' column esteem is break even with to 2
mean(Healthy_Cluster[Healthy_Cluster$Cluster1==2,"rating"])

```

```{r}

# # Calculating the cruel of 'rating' values for columns in 'Healthy_Cluster' dataframe where 'Cluster1' column esteem is break even with to 3
mean(Healthy_Cluster[Healthy_Cluster$Cluster1==3,"rating"])

```

```{r}

# Calculating the cruel of 'rating' values for columns in 'Healthy_Cluster' dataframe where 'Cluster1' column esteem is rise to to 4
mean(Healthy_Cluster[Healthy_Cluster$Cluster1==4,"rating"])

```

#Ready to take into thought cluster 1 since its cruel evaluations are the most noteworthy at 73.84446.